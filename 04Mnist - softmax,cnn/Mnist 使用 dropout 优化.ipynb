{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "\n",
    "dropout 通过暂时禁用一部分神经元的方式,达到防止模型过拟合的目的.\n",
    "使用的时候,我们有一个`keep_prob`保存所有神经元,并设置一个激活的比例.\n",
    "\n",
    "## 用法\n",
    "\n",
    "1. keep_prob=tf.placeholder(tf.float32)\n",
    "2. L1_drop = tf.nn.dropout(L1,keep_prob) \n",
    "3. sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "\n",
    "`keep_prob:1.0`相当于不使用 dropout,如果要使用可以设置为0~1之间的小数\n",
    "\n",
    "## 现象分析\n",
    "\n",
    "定义网络的时候刻意将网络定义地比较深,mnist数字分类只有60000张训练图片,输入大小也只有28x28,并不需要上千个神经元进行训练.\n",
    "\n",
    "用这样的方式人为来制造过拟合的现象,接下来看看试验结果.\n",
    "\n",
    "**不使用 dropout**\n",
    "\n",
    "```\n",
    "Iter 27,Testing Accuracy 0.9731,Training Accuracy 0.9954364\n",
    "Iter 28,Testing Accuracy 0.9733,Training Accuracy 0.9955091\n",
    "Iter 29,Testing Accuracy 0.9731,Training Accuracy 0.9955636\n",
    "Iter 30,Testing Accuracy 0.9732,Training Accuracy 0.9956545\n",
    "```\n",
    "可以看到训练集上的正确率很高到了 99% 以上,测试集准确率为97%.看上去也还好,估计是由于网络本身和任务本身并不复杂.\n",
    "\n",
    "**使用 dropout**\n",
    "\n",
    "```\n",
    "Iter 27,Testing Accuracy 0.9692,Training Accuracy 0.9762545\n",
    "Iter 28,Testing Accuracy 0.9689,Training Accuracy 0.9759273\n",
    "Iter 29,Testing Accuracy 0.9697,Training Accuracy 0.97687274\n",
    "Iter 30,Testing Accuracy 0.9713,Training Accuracy 0.9779091\n",
    "```\n",
    "和前面训练集的准确率相比降低到了97.8%,可以降低过拟合.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0805 10:39:07.844691 140401451972352 deprecation.py:323] From <ipython-input-2-c3538dc343e9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0805 10:39:07.845368 140401451972352 deprecation.py:323] From /home/aseit/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0805 10:39:07.845958 140401451972352 deprecation.py:323] From /home/aseit/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0805 10:39:07.996703 140401451972352 deprecation.py:323] From /home/aseit/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0805 10:39:07.997822 140401451972352 deprecation.py:323] From /home/aseit/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0805 10:39:08.026026 140401451972352 deprecation.py:323] From /home/aseit/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../dataset/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../dataset/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../dataset/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"../dataset/mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 10:39:18.253728 140401451972352 deprecation.py:506] From <ipython-input-3-0cfecddb3bba>:15: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0805 10:39:18.311351 140401451972352 deprecation.py:323] From <ipython-input-3-0cfecddb3bba>:33: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0,Testing Accuracy 0.9467,Training Accuracy 0.95614547\n",
      "Iter 1,Testing Accuracy 0.9582,Training Accuracy 0.9743091\n",
      "Iter 2,Testing Accuracy 0.9632,Training Accuracy 0.98212725\n",
      "Iter 3,Testing Accuracy 0.9654,Training Accuracy 0.98605454\n",
      "Iter 4,Testing Accuracy 0.9662,Training Accuracy 0.9888\n",
      "Iter 5,Testing Accuracy 0.9673,Training Accuracy 0.9902727\n",
      "Iter 6,Testing Accuracy 0.9681,Training Accuracy 0.9912182\n",
      "Iter 7,Testing Accuracy 0.9688,Training Accuracy 0.9918182\n",
      "Iter 8,Testing Accuracy 0.97,Training Accuracy 0.99225456\n",
      "Iter 9,Testing Accuracy 0.9704,Training Accuracy 0.9926\n",
      "Iter 10,Testing Accuracy 0.9695,Training Accuracy 0.99305457\n",
      "Iter 11,Testing Accuracy 0.9708,Training Accuracy 0.9934\n",
      "Iter 12,Testing Accuracy 0.9702,Training Accuracy 0.99365455\n",
      "Iter 13,Testing Accuracy 0.9718,Training Accuracy 0.99381816\n",
      "Iter 14,Testing Accuracy 0.9708,Training Accuracy 0.99398184\n",
      "Iter 15,Testing Accuracy 0.9722,Training Accuracy 0.9941091\n",
      "Iter 16,Testing Accuracy 0.9719,Training Accuracy 0.9942545\n",
      "Iter 17,Testing Accuracy 0.9718,Training Accuracy 0.99438184\n",
      "Iter 18,Testing Accuracy 0.9721,Training Accuracy 0.99454546\n",
      "Iter 19,Testing Accuracy 0.9719,Training Accuracy 0.99463636\n",
      "Iter 20,Testing Accuracy 0.9721,Training Accuracy 0.99472725\n",
      "Iter 21,Testing Accuracy 0.9722,Training Accuracy 0.9949273\n",
      "Iter 22,Testing Accuracy 0.9722,Training Accuracy 0.995\n",
      "Iter 23,Testing Accuracy 0.9716,Training Accuracy 0.99503636\n",
      "Iter 24,Testing Accuracy 0.9734,Training Accuracy 0.9951636\n",
      "Iter 25,Testing Accuracy 0.9728,Training Accuracy 0.9952\n",
      "Iter 26,Testing Accuracy 0.9734,Training Accuracy 0.99536365\n",
      "Iter 27,Testing Accuracy 0.9731,Training Accuracy 0.9954364\n",
      "Iter 28,Testing Accuracy 0.9733,Training Accuracy 0.9955091\n",
      "Iter 29,Testing Accuracy 0.9731,Training Accuracy 0.9955636\n",
      "Iter 30,Testing Accuracy 0.9732,Training Accuracy 0.9956545\n"
     ]
    }
   ],
   "source": [
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784,2000],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob) \n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([2000,2000],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob) \n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([2000,1000],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop,W3)+b3)\n",
    "L3_drop = tf.nn.dropout(L3,keep_prob) \n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([1000,10],stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop,W4)+b4)\n",
    "\n",
    "#二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大的值所在的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(31):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys =  mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "        \n",
    "        test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(test_acc) +\",Training Accuracy \" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0,Testing Accuracy 0.9178,Training Accuracy 0.9146909\n",
      "Iter 1,Testing Accuracy 0.929,Training Accuracy 0.92932725\n",
      "Iter 2,Testing Accuracy 0.9384,Training Accuracy 0.9358909\n",
      "Iter 3,Testing Accuracy 0.9395,Training Accuracy 0.94014543\n",
      "Iter 4,Testing Accuracy 0.9426,Training Accuracy 0.94463634\n",
      "Iter 5,Testing Accuracy 0.9453,Training Accuracy 0.94796365\n",
      "Iter 6,Testing Accuracy 0.9481,Training Accuracy 0.9521818\n",
      "Iter 7,Testing Accuracy 0.9495,Training Accuracy 0.95376366\n",
      "Iter 8,Testing Accuracy 0.9517,Training Accuracy 0.9557091\n",
      "Iter 9,Testing Accuracy 0.9534,Training Accuracy 0.95854545\n",
      "Iter 10,Testing Accuracy 0.9555,Training Accuracy 0.9603091\n",
      "Iter 11,Testing Accuracy 0.9584,Training Accuracy 0.9615091\n",
      "Iter 12,Testing Accuracy 0.958,Training Accuracy 0.9626909\n",
      "Iter 13,Testing Accuracy 0.9583,Training Accuracy 0.9638364\n",
      "Iter 14,Testing Accuracy 0.9609,Training Accuracy 0.96590906\n",
      "Iter 15,Testing Accuracy 0.9612,Training Accuracy 0.96763635\n",
      "Iter 16,Testing Accuracy 0.9629,Training Accuracy 0.96861815\n",
      "Iter 17,Testing Accuracy 0.9622,Training Accuracy 0.9689636\n",
      "Iter 18,Testing Accuracy 0.9649,Training Accuracy 0.9704546\n",
      "Iter 19,Testing Accuracy 0.9639,Training Accuracy 0.9714909\n",
      "Iter 20,Testing Accuracy 0.966,Training Accuracy 0.9716727\n",
      "Iter 21,Testing Accuracy 0.9652,Training Accuracy 0.97261816\n",
      "Iter 22,Testing Accuracy 0.9666,Training Accuracy 0.97354543\n",
      "Iter 23,Testing Accuracy 0.9668,Training Accuracy 0.97434545\n",
      "Iter 24,Testing Accuracy 0.9674,Training Accuracy 0.97418183\n",
      "Iter 25,Testing Accuracy 0.9678,Training Accuracy 0.97465456\n",
      "Iter 26,Testing Accuracy 0.9691,Training Accuracy 0.97516364\n",
      "Iter 27,Testing Accuracy 0.9692,Training Accuracy 0.9762545\n",
      "Iter 28,Testing Accuracy 0.9689,Training Accuracy 0.9759273\n",
      "Iter 29,Testing Accuracy 0.9697,Training Accuracy 0.97687274\n",
      "Iter 30,Testing Accuracy 0.9713,Training Accuracy 0.9779091\n"
     ]
    }
   ],
   "source": [
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784,2000],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob) \n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([2000,2000],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob) \n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([2000,1000],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop,W3)+b3)\n",
    "L3_drop = tf.nn.dropout(L3,keep_prob) \n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([1000,10],stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop,W4)+b4)\n",
    "\n",
    "#二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大的值所在的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(31):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys =  mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "        \n",
    "        test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(test_acc) +\",Training Accuracy \" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
